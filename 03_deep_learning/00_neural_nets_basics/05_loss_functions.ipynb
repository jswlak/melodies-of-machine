{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **What is a Loss Function?**\n",
        "\n",
        "\n",
        "*   Measures how well the model predictions match the true targets.\n",
        "*   Objective: minimize loss during training.\n",
        "*   Different tasks use different loss functions (regression vs classification).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZiDaFvrjDxYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Common Loss Functions**\n",
        "\n",
        "| Loss Function                       | Use Case                   | Formula / Explanation                                                                 |             |   |\n",
        "| ----------------------------------- | -------------------------- | -------------------------------------------------------------------------------------- | ----------- | - |\n",
        "| **Mean Squared Error (MSE)**        | Regression problems        | $\\frac{1}{n}\\sum (y - \\hat{y})^2$                                                     |             |   |\n",
        "| **Mean Absolute Error (MAE)**       | Regression                 | $\\frac{1}{n}\\sum \\left| y - \\hat{y} \\right|$                                          |             |   |\n",
        "| **Binary Cross-Entropy (Log Loss)** | Binary classification      | $-\\frac{1}{n} \\sum y \\log \\hat{y} + (1-y) \\log (1 - \\hat{y})$                         |             |   |\n",
        "| **Categorical Cross-Entropy**       | Multi-class classification | $-\\sum y_i \\log \\hat{y_i}$                                                            |             |   |\n",
        "| **Hinge Loss**                      | SVM classification         | $\\max(0, 1 - y \\cdot \\hat{y})$                                                        |             |   |\n",
        "                            |             |   |\n",
        "\n"
      ],
      "metadata": {
        "id": "dg5unltPECfj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementations**"
      ],
      "metadata": {
        "id": "ZMucw0coFJwM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VmMp1Ux6DgJF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def mse(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred)**2)\n",
        "\n",
        "def binary_cross_entropy(y_true, y_pred):\n",
        "    epsilon = 1e-8\n",
        "    return -np.mean(y_true * np.log(y_pred + epsilon) + (1 - y_true) * np.log(1 - y_pred + epsilon))\n",
        "\n",
        "def categorical_cross_entropy(y_true, y_pred):\n",
        "    epsilon = 1e-8\n",
        "    return -np.sum(y_true * np.log(y_pred + epsilon), axis=1).mean()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualizing Loss Functions**\n",
        "\n",
        "\n",
        "\n",
        "*   Plot MSE vs difference\n",
        "*   Plot cross-entropy vs prediction probability"
      ],
      "metadata": {
        "id": "-L9DuP5DFSdK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r0qxZ6vfFfdp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}